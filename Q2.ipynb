{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
    "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
    "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
    "\n",
    "\n",
    "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
    "\n",
    "\n",
    "**Student Name**: 400101956\n",
    "\n",
    "**Student ID**: Mohammad Morsali\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Implement your own Logistic Regression model, and test it on the given dataset of Logistic_question.csv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "# Define a custom Logistic Regression class\n",
    "class MyLogisticRegression:\n",
    "    # Initialize the class with learning rate, max epochs, and device parameters\n",
    "    def __init__(self, learning_rate=0.05, max_epochs=1000, device='cuda'):\n",
    "        self.rate = learning_rate  # Set the learning rate\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')  # Set the device to use for computation\n",
    "        self.epochs = max_epochs  # Set the maximum number of epochs for training\n",
    "        self.params = None  # Initialize the parameters to None\n",
    "\n",
    "    # Define the activation function (sigmoid function)\n",
    "    def activation(self, input_data):\n",
    "        input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
    "        return torch.sigmoid(input_data)  # Apply the sigmoid function\n",
    "\n",
    "    # Define the loss function (cross-entropy loss)\n",
    "    def calculate_loss(self, params, data, labels):\n",
    "        sample_count, feature_count = data.shape  # Get the number of samples and features\n",
    "        predictions = self.activation(data @ params)  # Calculate the predictions\n",
    "        predictions = torch.clamp(predictions, min=1e-7, max=1-1e-7)  # Clamp the predictions to avoid log(0)\n",
    "        # Calculate the cross-entropy loss\n",
    "        return -1/sample_count * (torch.sum(labels * torch.log(predictions) + (1 - labels) * torch.log(1 - predictions)))  # Return the loss\n",
    "\n",
    "    # Define the function to calculate the gradient\n",
    "    def calculate_gradient(self, data, labels):\n",
    "        sample_count, feature_count = data.shape  # Get the number of samples and features\n",
    "        predictions = self.activation(data @ self.params)  # Calculate the predictions\n",
    "        gradient = torch.zeros(self.params.shape[0], device=self.device, requires_grad=True)  # Initialize the gradient\n",
    "        with torch.no_grad():  # No need to calculate gradients in this block\n",
    "            for i in range(feature_count):  # For each feature\n",
    "                temp =  data[:,i]  # Get the i-th feature\n",
    "                # Calculate the gradient for the i-th feature\n",
    "                gradient[i] = 1/sample_count *  torch.tensordot((predictions-labels), temp, dims=1)\n",
    "        return gradient  # Return the gradient\n",
    "\n",
    "    # Define the function to train the model\n",
    "    def train(self, X, y):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Convert X and y to PyTorch tensors\n",
    "        X_tensor = torch.from_numpy(X).float().to(self.device)\n",
    "        y_tensor = torch.from_numpy(np.array(y)).long().to(self.device)\n",
    "\n",
    "        # Initialize the parameters to zeros\n",
    "        self.params = torch.zeros(n, device=self.device, requires_grad=True)\n",
    "\n",
    "        # Perform gradient descent for a number of iterations\n",
    "        for _ in range(self.epochs):\n",
    "            # Compute the gradient\n",
    "            grad = self.calculate_gradient(X_tensor, y_tensor)\n",
    "\n",
    "            # Update the parameters using the learning rate and gradient\n",
    "            with torch.no_grad():\n",
    "                self.params -= self.rate * grad\n",
    "\n",
    "    # Define the function to classify the data\n",
    "    def classify(self, data):\n",
    "        data = np.insert(data, 0, np.ones((data.shape[0])), axis=1)  # Insert a column of ones at the beginning of the data\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32, device=self.device)  # Convert the data to a tensor\n",
    "        predictions = self.activation(data_tensor @ self.params)  # Calculate the predictions\n",
    "      \n",
    "        return  (predictions >= 0.5).long()  # Classify the predictions\n",
    "\n",
    "    # Define the function to calculate the accuracy\n",
    "    def accuracy(self, data, labels):\n",
    "        predicted_labels = self.classify(data)  # Get the predicted labels\n",
    "        return  (predicted_labels == labels).float().mean()  # Calculate the accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Test your model on the given dataset. You must split your data into train and test, with a 0.2 split, then normalize your data using X_train data. Finally, report 4 different evaluation metrics of the model on the test set. (You might want to first make the Target column binary!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.925\n",
      "Model Precision: 0.921\n",
      "Model Recall: 1.000\n",
      "Model F1-Score: 0.959\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "# Load the dataset from a CSV file\n",
    "dataset = pd.read_csv(\"Q2/Logistic_question.csv\")\n",
    "\n",
    "# Convert the 'Target' column to binary (1 if value > 0.5, else 0)\n",
    "dataset['Target'] = dataset['Target'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(dataset.drop('Target', axis=1), dataset['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a StandardScaler for normalizing the features\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "# Normalize the training features using the StandardScaler\n",
    "train_features_norm = normalizer.fit_transform(train_features)\n",
    "\n",
    "# Normalize the testing features using the same StandardScaler\n",
    "test_features_norm = normalizer.transform(test_features)\n",
    "\n",
    "# Initialize a custom Logistic Regression model\n",
    "log_reg_model = MyLogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model using the normalized training features and labels\n",
    "log_reg_model.train(train_features_norm, train_labels)\n",
    "\n",
    "# Use the trained model to predict labels for the normalized testing features\n",
    "predicted_labels = log_reg_model.classify(test_features_norm)\n",
    "\n",
    "# Calculate the accuracy of the model's predictions\n",
    "acc = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the precision of the model's predictions\n",
    "prec = precision_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the recall of the model's predictions\n",
    "rec = recall_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the F1 score of the model's predictions\n",
    "f1_metric = f1_score(test_labels, predicted_labels)\n",
    "\n",
    "# Store the metrics in a dictionary\n",
    "metrics = {\"Model Accuracy\": acc, \"Model Precision\": prec, \"Model Recall\": rec, \"Model F1-Score\": f1_metric}\n",
    "# Loop over the dictionary and print each metric\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** What are each of your used evaluation metrics? And for each one, mention situations in which they convey more data on the model performance in specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your answer:** \n",
    "\n",
    "\n",
    "**Accuracy:** Beyond its fundamental definition, Accuracy warrants scrutiny in various real-world scenarios. For instance, in applications like fraud detection, where fraudulent transactions represent a minuscule fraction of the total, a high Accuracy score might be misleading. Here, even a model that indiscriminately labels all transactions as legitimate could achieve a high Accuracy due to the overwhelming prevalence of true negatives. This phenomenon underscores the importance of considering the dataset's class distribution and the practical implications of misclassifications. Moreover, in contexts where model interpretability is crucial, Accuracy alone might not suffice. Supplementary techniques, such as confusion matrices or ROC curves, can offer deeper insights into a model's performance across different thresholds.\n",
    "\n",
    "**Precision:** While Precision illuminates a model's ability to correctly identify positive instances, its interpretation can vary based on the application domain. For instance, in healthcare, Precision assumes paramount importance when diagnosing rare diseases. A high Precision ensures that a positive diagnosis is highly reliable, minimizing the chances of unnecessary treatments or interventions. However, achieving high Precision often comes at the expense of Recall, as the model becomes more conservative in its predictions. Consequently, striking the right balance between Precision and Recall becomes imperative, necessitating a nuanced understanding of the domain-specific trade-offs.\n",
    "\n",
    "**Recall (Sensitivity or True Positive Rate):** In fields like anomaly detection or cybersecurity, Recall holds significant sway, particularly when the cost of missing positive instances is exorbitant. Consider a cybersecurity system tasked with identifying malware attacks. Here, a high Recall ensures that the system effectively captures the majority of malicious activities, minimizing the risk of undetected threats. However, an overemphasis on Recall might lead to an influx of false positives, inundating security personnel with spurious alerts. Thus, optimizing Recall necessitates a delicate balancing act, wherein the model remains vigilant against threats while mitigating the burden of false alarms.\n",
    "\n",
    "**F1 Score:** Beyond its role as a harmonic mean, the F1 Score encapsulates the intricacies of Precision and Recall interplay. However, its utility extends beyond binary classification tasks to multiclass or imbalanced datasets. For instance, in sentiment analysis, where class imbalance is pervasive, the F1 Score offers a robust performance metric, considering both the model's ability to correctly identify each sentiment class and its capacity to balance precision and recall across classes. Moreover, in ensemble learning or model selection frameworks, the F1 Score serves as a unifying criterion, facilitating comparisons across diverse models and algorithms.\n",
    "\n",
    "In sum, while these evaluation metrics provide a solid foundation for assessing model performance, their effective utilization hinges on a nuanced understanding of the underlying data distribution, domain-specific considerations, and the broader context of the problem at hand. By incorporating supplementary techniques, considering real-world implications, and iteratively refining model performance, practitioners can harness the full potential of these metrics to drive impactful decision-making and foster continuous improvement in machine learning endeavors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:**. Now test the built-in function of Python for Logistic Regression, and report all the same metrics used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.950\n",
      "Model Precision: 0.946\n",
      "Model Recall: 1.000\n",
      "Model F1-Score: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "dataset = pd.read_csv(\"Q2/Logistic_question.csv\")\n",
    "\n",
    "# Convert the 'Target' column to binary (1 if value > 0.5, else 0)\n",
    "dataset['Target'] = dataset['Target'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(dataset.drop('Target', axis=1), dataset['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a StandardScaler for normalizing the features\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "# Normalize the training features using the StandardScaler\n",
    "train_features_norm = normalizer.fit_transform(train_features)\n",
    "\n",
    "# Normalize the testing features using the same StandardScaler\n",
    "test_features_norm = normalizer.transform(test_features)\n",
    "\n",
    "# Initialize a built-in Logistic Regression model\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model using the normalized training features and labels\n",
    "log_reg_model.fit(train_features_norm, train_labels)\n",
    "\n",
    "# Use the trained model to predict labels for the normalized testing features\n",
    "predicted_labels = log_reg_model.predict(test_features_norm)\n",
    "\n",
    "# Calculate the accuracy of the model's predictions\n",
    "acc = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the precision of the model's predictions\n",
    "prec = precision_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the recall of the model's predictions\n",
    "rec = recall_score(test_labels, predicted_labels)\n",
    "\n",
    "# Calculate the F1 score of the model's predictions\n",
    "f1_metric = f1_score(test_labels, predicted_labels)\n",
    "\n",
    "# Store the metrics in a dictionary\n",
    "metrics = {\"Model Accuracy\": acc, \"Model Precision\": prec, \"Model Recall\": rec, \"Model F1-Score\": f1_metric}\n",
    "\n",
    "# Loop over the dictionary and print each metric\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** Compare your function with the built-in function. On the matters of performance and parameters. Briefly explain what the parameters of the built-in function are and how they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your answer:**\n",
    "\n",
    "**Exploring Model Performance**:\n",
    "\n",
    "- **Evaluating Accuracy**: By scrutinizing the accuracy achieved by both implementations on the test set, we unveil vital insights into their performance prowess. An elevated accuracy quotient not only signifies the model's adeptness in making correct classifications but also serves as a yardstick for its overall effectiveness in discerning patterns within the data. It stands as a beacon guiding us towards models that exhibit superior performance in classification tasks.\n",
    "\n",
    "- **Diving into Precision, Recall, and F1 Score**: These metrics delve deeper into the intricate facets of model performance, offering a multifaceted lens through which to assess their efficacy. Precision, with its emphasis on minimizing false positives, paints a picture of the model's precision in correctly identifying positive instances. Conversely, Recall, with its focus on mitigating false negatives, highlights the model's sensitivity in capturing all positive instances. The F1 Score, a harmonious blend of Precision and Recall, strikes a delicate equilibrium, encapsulating the model's ability to navigate the trade-off between them. Together, these metrics furnish a comprehensive portrait of the model's performance landscape, enabling nuanced decision-making in the realm of classification tasks.\n",
    "\n",
    "**Unraveling Parameter Dynamics**:\n",
    "\n",
    "- **Unveiling Custom Logistic Regression (`MyLogisticRegression`) Parameters**: Delving into the intricacies of custom logistic regression parameters unravels a tapestry of variables that wield significant influence over the model's behavior. The `learning_rate`, akin to a conductor orchestrating the gradient descent symphony, dictates the magnitude of each step, thereby sculpting the trajectory towards convergence. However, traversing this path demands a delicate balance, for while higher learning rates accelerate the journey, they risk overshooting the optimal solution. Meanwhile, the `epochs` parameter serves as a compass guiding the model through the dataset landscape. Yet, treading too heavily upon this terrain may lead to overfitting, underscoring the need for judicious calibration to navigate the convergence-versus-overfitting conundrum.\n",
    "\n",
    "- **Deciphering Built-in Logistic Regression (`LogisticRegression`) Parameters**: As we unravel the array of built-in logistic regression parameters, we encounter a labyrinth of choices that wield profound implications for model optimization. The `penalty` parameter serves as a gatekeeper, dictating the norm used in regularization, with 'l2' standing as the default sentinel. Meanwhile, `C`, the inverse of regularization strength, holds sway over the model's propensity towards regularization, with smaller values signaling a more robust defense against overfitting. The `solver` parameter, akin to an alchemist concocting optimization elixirs, offers an array of algorithms, each tailored to suit diverse optimization landscapes. As the model embarks on its optimization odyssey, `max_iter` stands as a sentinel, guarding against infinite iterations, with its default value of 100 ensuring convergence within reasonable bounds.\n",
    "\n",
    "**Navigating the Parameter Panorama**:\n",
    "\n",
    "- The intricate dance between custom and built-in logistic regression parameters orchestrates a symphony of model optimization, with each parameter wielding a unique influence over convergence dynamics and model robustness. In the custom implementation realm, the `learning_rate` and `epochs` parameters reign supreme, dictating the tempo and trajectory of the optimization journey. Meanwhile, the built-in implementation landscape unveils a rich tapestry of parameters, each offering a gateway into the labyrinthine realms of regularization, optimization strategy, and convergence criteria.\n",
    "\n",
    "- In the broader spectrum, scikit-learn's `LogisticRegression` emerges as a bastion of versatility, offering an arsenal of solvers and regularization techniques finely tuned to navigate the complexities of real-world datasets. However, the allure of custom implementations lies in their transparency and tailor-made customization options, catering to the idiosyncratic demands of specific use cases.\n",
    "\n",
    "**Pioneering Performance Paths**:\n",
    "\n",
    "- From a performance perspective, scikit-learn's battle-tested `LogisticRegression` implementation emerges as a beacon of optimization and robustness, forged in the crucible of meticulous testing and optimization endeavors. Its versatile toolkit, coupled with efficient handling of edge cases and optimizations, positions it as the default choice for most use cases. However, the allure of custom implementations persists, offering a canvas for experimentation and research pursuits, where bespoke requirements demand a tailored approach. In the quest for model performance excellence, the choice between built-in and custom implementations stands as a pivotal juncture, guiding practitioners towards novel frontiers in machine learning innovation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Implement your own Multinomial Logistic Regression model. Your model must be able to handle any number of labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class MyMultinomialLogisticRegression:\n",
    "    def __init__(self, lr=0.01, iterations=100):\n",
    "        self.lr = lr  # Learning rate for gradient descent\n",
    "        self.iterations = iterations  # Number of iterations for gradient descent\n",
    "        self.params = None  # Weights for the logistic regression model\n",
    "        self.intercept = None  # Bias term for the logistic regression model\n",
    "        self.classes = None  # Number of unique classes in the target variable\n",
    "        self.loss = []  # Loss during training\n",
    "\n",
    "    def softmax_func(self, scores):\n",
    "        # Compute softmax scores for each class\n",
    "        return np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n",
    "\n",
    "    def train(self, features, target):\n",
    "        # Input validation\n",
    "        assert isinstance(features, np.ndarray), \"Features must be a numpy array\"\n",
    "        assert isinstance(target, np.ndarray), \"Target must be a numpy array\"\n",
    "        assert len(features.shape) == 2, \"Features must be a 2D array\"\n",
    "        assert len(target.shape) == 1, \"Target must be a 1D array\"\n",
    "        assert features.shape[0] == target.shape[0], \"Features and target must have the same number of samples\"\n",
    "\n",
    "        samples, features_num = features.shape\n",
    "        self.classes = len(np.unique(target))\n",
    "        self.params = np.zeros((features_num, self.classes))\n",
    "        self.intercept = np.zeros(self.classes)\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            # Compute the predicted probabilities using the current parameters\n",
    "            linear_scores = np.dot(features, self.params) + self.intercept\n",
    "            predictions = self.softmax_func(linear_scores)\n",
    "\n",
    "            # Compute the gradient of the loss with respect to the parameters\n",
    "            error = predictions - np.eye(self.classes)[target]\n",
    "            gradient_w = (1 / samples) * np.dot(features.T, error)\n",
    "            gradient_b = (1 / samples) * np.sum(error, axis=0)\n",
    "\n",
    "            # Update the parameters using the computed gradients\n",
    "            self.params -= self.lr * gradient_w\n",
    "            self.intercept -= self.lr * gradient_b\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = -np.sum(np.log(predictions[np.arange(samples), target])) / samples\n",
    "            self.loss.append(loss)\n",
    "\n",
    "            # Logging\n",
    "            if i % 10 == 0:\n",
    "                logging.info(f\"Iteration {i}, loss: {loss}\")\n",
    "\n",
    "    def predict_prob(self, features):\n",
    "        # Compute the predicted probabilities for each class\n",
    "        return self.softmax_func(np.dot(features, self.params) + self.intercept)\n",
    "\n",
    "    def classify(self, features):\n",
    "        # Predict the class with the highest probability\n",
    "        return np.argmax(self.predict_prob(features), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Test your model on the given dataset. Do the same as the previous part, but here you might want to first make the Target column quantized into $i$ levels. Change $i$ from 2 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0, loss: 0.6931471805599453\n",
      "INFO:root:Iteration 10, loss: 0.5849909684314898\n",
      "INFO:root:Iteration 20, loss: 0.5167974394845746\n",
      "INFO:root:Iteration 30, loss: 0.4715329266160378\n",
      "INFO:root:Iteration 40, loss: 0.43985338225348125\n",
      "INFO:root:Iteration 50, loss: 0.41665002450470273\n",
      "INFO:root:Iteration 60, loss: 0.39901275175555967\n",
      "INFO:root:Iteration 70, loss: 0.3851982542597663\n",
      "INFO:root:Iteration 80, loss: 0.37411077300853124\n",
      "INFO:root:Iteration 90, loss: 0.36503157998375857\n",
      "INFO:root:Iteration 0, loss: 1.0986122886681096\n",
      "INFO:root:Iteration 10, loss: 0.9926830435704987\n",
      "INFO:root:Iteration 20, loss: 0.9180546507025232\n",
      "INFO:root:Iteration 30, loss: 0.8641531754118663\n",
      "INFO:root:Iteration 40, loss: 0.8240565975307252\n",
      "INFO:root:Iteration 50, loss: 0.793343308158318\n",
      "INFO:root:Iteration 60, loss: 0.7691707151903746\n",
      "INFO:root:Iteration 70, loss: 0.7496753931096686\n",
      "INFO:root:Iteration 80, loss: 0.7336062621503323\n",
      "INFO:root:Iteration 90, loss: 0.720102672137483\n",
      "INFO:root:Iteration 0, loss: 1.3862943611198906\n",
      "INFO:root:Iteration 10, loss: 1.267985885826807\n",
      "INFO:root:Iteration 20, loss: 1.1790002444723668\n",
      "INFO:root:Iteration 30, loss: 1.110696660484266\n",
      "INFO:root:Iteration 40, loss: 1.0569762281737811\n",
      "INFO:root:Iteration 50, loss: 1.0136630469960823\n",
      "INFO:root:Iteration 60, loss: 0.9779090351511981\n",
      "INFO:root:Iteration 70, loss: 0.9477541766503552\n",
      "INFO:root:Iteration 80, loss: 0.9218296203529206\n",
      "INFO:root:Iteration 90, loss: 0.899163150764114\n",
      "INFO:root:Iteration 0, loss: 1.6094379124341\n",
      "INFO:root:Iteration 10, loss: 1.5020799516658383\n",
      "INFO:root:Iteration 20, loss: 1.4196940663506432\n",
      "INFO:root:Iteration 30, loss: 1.3554905432332895\n",
      "INFO:root:Iteration 40, loss: 1.304492368276326\n",
      "INFO:root:Iteration 50, loss: 1.2631627483915435\n",
      "INFO:root:Iteration 60, loss: 1.229008382613852\n",
      "INFO:root:Iteration 70, loss: 1.2002641830927114\n",
      "INFO:root:Iteration 80, loss: 1.175667617081611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization Level: 2\n",
      "==============================\n",
      "Model Accuracy: 0.950\n",
      "Model Precision: 0.951\n",
      "Model Recall: 0.950\n",
      "Model F1-Score: 0.950\n",
      "==============================\n",
      "\n",
      "Quantization Level: 3\n",
      "==============================\n",
      "Model Accuracy: 0.750\n",
      "Model Precision: 0.816\n",
      "Model Recall: 0.750\n",
      "Model F1-Score: 0.665\n",
      "==============================\n",
      "\n",
      "Quantization Level: 4\n",
      "==============================\n",
      "Model Accuracy: 0.762\n",
      "Model Precision: 0.829\n",
      "Model Recall: 0.762\n",
      "Model F1-Score: 0.723\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 90, loss: 1.15430364938616\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Iteration 0, loss: 1.791759469228055\n",
      "INFO:root:Iteration 10, loss: 1.6811921719162783\n",
      "INFO:root:Iteration 20, loss: 1.5942974535393184\n",
      "INFO:root:Iteration 30, loss: 1.5250048980508368\n",
      "INFO:root:Iteration 40, loss: 1.4687528341409721\n",
      "INFO:root:Iteration 50, loss: 1.4222159665988907\n",
      "INFO:root:Iteration 60, loss: 1.3829941278148623\n",
      "INFO:root:Iteration 70, loss: 1.3493527284605293\n",
      "INFO:root:Iteration 80, loss: 1.320029321614856\n",
      "INFO:root:Iteration 90, loss: 1.2940959008255457\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Iteration 0, loss: 1.945910149055314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization Level: 5\n",
      "==============================\n",
      "Model Accuracy: 0.487\n",
      "Model Precision: 0.319\n",
      "Model Recall: 0.487\n",
      "Model F1-Score: 0.371\n",
      "==============================\n",
      "\n",
      "Quantization Level: 6\n",
      "==============================\n",
      "Model Accuracy: 0.487\n",
      "Model Precision: 0.470\n",
      "Model Recall: 0.487\n",
      "Model F1-Score: 0.381\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10, loss: 1.8409254301653082\n",
      "INFO:root:Iteration 20, loss: 1.7582387358159124\n",
      "INFO:root:Iteration 30, loss: 1.6923750881805795\n",
      "INFO:root:Iteration 40, loss: 1.6391494568135798\n",
      "INFO:root:Iteration 50, loss: 1.5954523372607354\n",
      "INFO:root:Iteration 60, loss: 1.558997527996094\n",
      "INFO:root:Iteration 70, loss: 1.5281051317430019\n",
      "INFO:root:Iteration 80, loss: 1.5015349118626509\n",
      "INFO:root:Iteration 90, loss: 1.478364309120197\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Iteration 0, loss: 2.0794415416798353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization Level: 7\n",
      "==============================\n",
      "Model Accuracy: 0.388\n",
      "Model Precision: 0.219\n",
      "Model Recall: 0.388\n",
      "Model F1-Score: 0.236\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 10, loss: 1.9722522003556757\n",
      "INFO:root:Iteration 20, loss: 1.8867750594951722\n",
      "INFO:root:Iteration 30, loss: 1.8178396336373268\n",
      "INFO:root:Iteration 40, loss: 1.7614459539680065\n",
      "INFO:root:Iteration 50, loss: 1.714589969725631\n",
      "INFO:root:Iteration 60, loss: 1.6750421957808115\n",
      "INFO:root:Iteration 70, loss: 1.6411507452199185\n",
      "INFO:root:Iteration 80, loss: 1.611686760983093\n",
      "INFO:root:Iteration 90, loss: 1.5857295449067308\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Iteration 0, loss: 2.197224577336219\n",
      "INFO:root:Iteration 10, loss: 2.094510766493125\n",
      "INFO:root:Iteration 20, loss: 2.012334191242469\n",
      "INFO:root:Iteration 30, loss: 1.945895947388329\n",
      "INFO:root:Iteration 40, loss: 1.8914573357941442\n",
      "INFO:root:Iteration 50, loss: 1.8461925164744415\n",
      "INFO:root:Iteration 60, loss: 1.8079921211251258\n",
      "INFO:root:Iteration 70, loss: 1.7752847362587474\n",
      "INFO:root:Iteration 80, loss: 1.746895109684805\n",
      "INFO:root:Iteration 90, loss: 1.721938005487275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization Level: 8\n",
      "==============================\n",
      "Model Accuracy: 0.375\n",
      "Model Precision: 0.460\n",
      "Model Recall: 0.375\n",
      "Model F1-Score: 0.259\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Iteration 0, loss: 2.302585092994046\n",
      "INFO:root:Iteration 10, loss: 2.201457548953722\n",
      "INFO:root:Iteration 20, loss: 2.120104235843334\n",
      "INFO:root:Iteration 30, loss: 2.0539575944220703\n",
      "INFO:root:Iteration 40, loss: 1.9994440851482378\n",
      "INFO:root:Iteration 50, loss: 1.9538554390862863\n",
      "INFO:root:Iteration 60, loss: 1.9151660217769222\n",
      "INFO:root:Iteration 70, loss: 1.8818639587467179\n",
      "INFO:root:Iteration 80, loss: 1.852816106017125\n",
      "INFO:root:Iteration 90, loss: 1.8271667277509962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization Level: 9\n",
      "==============================\n",
      "Model Accuracy: 0.300\n",
      "Model Precision: 0.106\n",
      "Model Recall: 0.300\n",
      "Model F1-Score: 0.157\n",
      "==============================\n",
      "\n",
      "Quantization Level: 10\n",
      "==============================\n",
      "Model Accuracy: 0.275\n",
      "Model Precision: 0.216\n",
      "Model Recall: 0.275\n",
      "Model F1-Score: 0.164\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Set logging level\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "dataset = pd.read_csv(\"Q2/Logistic_question.csv\")\n",
    "\n",
    "# Initialize a StandardScaler for normalizing the features\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "# Initialize num_levels\n",
    "num_levels = 2\n",
    "\n",
    "while num_levels < 11:\n",
    "    # Quantize the 'Target' column into 'num_levels' levels\n",
    "    dataset[f'Target_{num_levels}'] = pd.qcut(dataset['Target'], num_levels, labels=False)\n",
    "\n",
    "    # Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(dataset.drop(['Target', f'Target_{num_levels}'], axis=1), dataset[f'Target_{num_levels}'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalize the training features using the StandardScaler\n",
    "    train_features_norm = normalizer.fit_transform(train_features)\n",
    "\n",
    "    # Normalize the testing features using the same StandardScaler\n",
    "    test_features_norm = normalizer.transform(test_features)\n",
    "\n",
    "    # Initialize a custom Logistic Regression model\n",
    "    log_reg_model = MyMultinomialLogisticRegression()\n",
    "\n",
    "    # Train the Logistic Regression model using the normalized training features and labels\n",
    "    log_reg_model.train(train_features_norm, train_labels.values)\n",
    "\n",
    "    # Use the trained model to predict labels for the normalized testing features\n",
    "    predicted_labels = log_reg_model.classify(test_features_norm)\n",
    "\n",
    "    # Calculate the accuracy of the model's predictions\n",
    "    acc = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "    # Calculate the precision of the model's predictions\n",
    "    prec = precision_score(test_labels, predicted_labels, average='weighted', zero_division='warn')\n",
    "\n",
    "    # Calculate the recall of the model's predictions\n",
    "    rec = recall_score(test_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    # Calculate the F1 score of the model's predictions\n",
    "    f1_metric = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    # Store the metrics in a dictionary\n",
    "    metrics = {\"Model Accuracy\": acc, \"Model Precision\": prec, \"Model Recall\": rec, \"Model F1-Score\": f1_metric}\n",
    "\n",
    "    # Print the quantization level\n",
    "    print(f\"\\nQuantization Level: {num_levels}\\n\" + \"=\"*30)\n",
    "\n",
    "    # Loop over the dictionary and print each metric\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # Increment num_levels\n",
    "    num_levels += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** Report for which $i$ your model performs best. Describe and analyze the results! You could use visualizations or any other method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your answer:**\n",
    "\n",
    "\n",
    "as printed upper  for i=2 our model performs best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Going a little further!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we download Adult income dataset from Kaggle! In order to do this create an account on this website, and create an API. A file named kaggle.json will be downloaded to your device. Then use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.upload()  # Use this to select the kaggle.json file from your computer\n",
    "#!mkdir -p ~/.kaggle\n",
    "#!cp kaggle.json ~/.kaggle/\n",
    "#!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then use this code to automatically download the dataset into Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d wenruliu/adult-income-dataset\n",
    "#!unzip /content/adult-income-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Determine the number of null entries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  educational-num  \\\n",
       "0       25       Private  226802          11th                7   \n",
       "1       38       Private   89814       HS-grad                9   \n",
       "2       28     Local-gov  336951    Assoc-acdm               12   \n",
       "3       44       Private  160323  Some-college               10   \n",
       "4       18           NaN  103497  Some-college               10   \n",
       "...    ...           ...     ...           ...              ...   \n",
       "48837   27       Private  257302    Assoc-acdm               12   \n",
       "48838   40       Private  154374       HS-grad                9   \n",
       "48839   58       Private  151910       HS-grad                9   \n",
       "48840   22       Private  201490       HS-grad                9   \n",
       "48841   52  Self-emp-inc  287927       HS-grad                9   \n",
       "\n",
       "           marital-status         occupation relationship   race  gender  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0                 0             0              40  United-States  <=50K  \n",
       "1                 0             0              50  United-States  <=50K  \n",
       "2                 0             0              40  United-States   >50K  \n",
       "3              7688             0              40  United-States   >50K  \n",
       "4                 0             0              30  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "48837             0             0              38  United-States  <=50K  \n",
       "48838             0             0              40  United-States   >50K  \n",
       "48839             0             0              40  United-States  <=50K  \n",
       "48840             0             0              20  United-States  <=50K  \n",
       "48841         15024             0              40  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "df = pd.read_csv('adult.csv', na_values='?')\n",
    "print(df.isnull().sum().sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** In many widely used datasets there are a lot of null entries. Propose 5 methods by which, one could deal with this problem. Briefly explain how do you decide which one to use in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your answer:**\n",
    "\n",
    "**Navigating Missing Data:**\n",
    "\n",
    "1. **Deletion Strategy**: A common tactic, deletion involves the outright removal of rows or columns containing null entries. While it's a straightforward solution, its simplicity belies potential pitfalls. Deleting data indiscriminately may lead to the loss of valuable insights, especially if the null values are sporadically distributed or if they represent a significant portion of the dataset. Reserve deletion for cases where null entries are negligible or where their impact on the analysis is minimal.\n",
    "\n",
    "2. **Imputation Techniques**: Imputation offers a range of methodologies to fill in missing values with estimated substitutes. Popular imputation strategies include:\n",
    "   - **Mean Imputation**: Replacing null values with the mean of the feature.\n",
    "   - **Median Imputation**: Substituting null entries with the median value of the feature.\n",
    "   - **Mode Imputation**: Filling in missing values with the most frequent value in the feature.\n",
    "   - **User-Defined Constant**: Introducing a predefined value as a placeholder for missing data.\n",
    "   \n",
    "   Imputation helps to preserve data integrity while mitigating the impact of missing values. It's a preferred choice when dealing with a substantial amount of missing data, provided that the imputed values can be reasonably inferred from the existing dataset.\n",
    "\n",
    "3. **Prediction Methods**: Predictive techniques leverage machine learning algorithms to estimate missing values based on the relationships observed within the dataset. This approach encompasses:\n",
    "   - **Regression**: Utilizing regression models to predict missing values based on other features.\n",
    "   - **K-Nearest Neighbors (KNN)**: Imputing missing values by averaging the values of the nearest neighbors in the feature space.\n",
    "   - **Decision Trees**: Employing decision trees to infer missing values through recursive partitioning of the dataset.\n",
    "   \n",
    "   Prediction methods are suitable when missing data exhibits discernible patterns that can be learned from other features. However, they require computational resources for model training and may introduce complexity into the imputation process.\n",
    "\n",
    "4. **Interpolation Strategies**: Interpolation techniques estimate missing values by interpolating between neighboring data points. Various interpolation methods include:\n",
    "   - **Linear Interpolation**: Estimating missing values based on linear relationships between adjacent data points.\n",
    "   - **Spline Interpolation**: Utilizing piecewise polynomial functions to interpolate missing values.\n",
    "   - **Time-Series Interpolation**: Employing specialized methods like linear or seasonal interpolation for time-series datasets.\n",
    "   \n",
    "   Interpolation is particularly effective for sequential or time-series data, where missing values follow a predictable trend or pattern.\n",
    "\n",
    "5. **Flagging Approach**: Flagging introduces an additional binary indicator variable to denote the presence or absence of missing values. This method allows the model to learn the significance of missingness as a distinct feature. Flagging is beneficial when the absence of data itself conveys valuable information for the analysis or prediction task.\n",
    "\n",
    "6. **Multiple Imputation**: Multiple imputation involves generating multiple imputed datasets, each with different imputed values, and then combining the results to produce a final estimate. This technique accounts for uncertainty in imputed values and yields more robust estimates compared to single imputation methods.\n",
    "\n",
    "7. **Domain-Specific Imputation**: Tailoring imputation methods to the specific characteristics of the dataset or domain can enhance imputation accuracy. For example, in healthcare data, imputing missing values based on medical knowledge or expert guidelines may yield more clinically meaningful results.\n",
    "\n",
    "By understanding the nuances of these methods and selecting the appropriate approach based on the nature of the dataset and the objectives of the analysis, practitioners can effectively navigate the challenges posed by missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Handle null entries using your best method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation successful. No NA entries remaining.\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "# For each numeric column, replace any null (NA) values with the mean value of that column\n",
    "df[df.columns[df.dtypes != 'object']] = df[df.columns[df.dtypes != 'object']].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Initialize an index for the while loop\n",
    "feature_index = 0\n",
    "\n",
    "# Start a while loop that will continue as long as feature_index is less than the number of non-numeric features\n",
    "while feature_index < len(df.columns[df.dtypes == 'object']):\n",
    "    # Get the name of the current feature\n",
    "    feature = df.columns[df.dtypes == 'object'][feature_index]\n",
    "    \n",
    "    # Find the most frequent value (mode) in the current feature\n",
    "    most_frequent = df[feature].value_counts().idxmax()\n",
    "    \n",
    "    # Replace any null (NA) values in the current feature with its most frequent value\n",
    "    df[feature].fillna(value=most_frequent, inplace=True)\n",
    "    \n",
    "    # Increment the feature_index to move to the next feature in the next iteration\n",
    "    feature_index += 1\n",
    "\n",
    "# Calculate the total number of null (NA) values remaining in the dataset\n",
    "remaining_na = df.isna().values.sum()\n",
    "\n",
    "# If there are no null values remaining, print a success message\n",
    "if remaining_na == 0:\n",
    "    print(\"Imputation successful. No NA entries remaining.\")\n",
    "# If there are still null values remaining, print a message indicating the number of remaining null values\n",
    "else:\n",
    "    print(f\"Imputation incomplete. {remaining_na} NA entries still exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Convert categorical features to numerical values. Split the dataset with 80-20 portion. Normalize all the data using X_train. Use the built-in Logistic Regression function and GridSearchCV to train your model, and report the parameters, train and test accuracy of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing values have been successfully handled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>226802</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>89814</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>336951</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>160323</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>103497</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>287927</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0       25          3  226802          1                7               4   \n",
       "1       38          3   89814         11                9               2   \n",
       "2       28          1  336951          7               12               2   \n",
       "3       44          3  160323         15               10               2   \n",
       "4       18          3  103497         15               10               4   \n",
       "...    ...        ...     ...        ...              ...             ...   \n",
       "48837   27          3  257302          7               12               2   \n",
       "48838   40          3  154374         11                9               2   \n",
       "48839   58          3  151910         11                9               6   \n",
       "48840   22          3  201490         11                9               4   \n",
       "48841   52          4  287927         11                9               2   \n",
       "\n",
       "       occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0               6             3     2       1             0             0   \n",
       "1               4             0     4       1             0             0   \n",
       "2              10             0     4       1             0             0   \n",
       "3               6             0     2       1          7688             0   \n",
       "4               9             3     4       0             0             0   \n",
       "...           ...           ...   ...     ...           ...           ...   \n",
       "48837          12             5     4       0             0             0   \n",
       "48838           6             0     4       1             0             0   \n",
       "48839           0             4     4       0             0             0   \n",
       "48840           0             3     4       1             0             0   \n",
       "48841           3             5     4       0         15024             0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0                  40              38       0  \n",
       "1                  50              38       0  \n",
       "2                  40              38       1  \n",
       "3                  40              38       1  \n",
       "4                  30              38       0  \n",
       "...               ...             ...     ...  \n",
       "48837              38              38       0  \n",
       "48838              40              38       1  \n",
       "48839              40              38       0  \n",
       "48840              20              38       0  \n",
       "48841              40              38       1  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values and create a new DataFrame\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Create a copy of the cleaned DataFrame for encoding categorical features\n",
    "df_encoded = df_clean.copy()\n",
    "\n",
    "# Initialize an index for the while loop\n",
    "feature_index = 0\n",
    "\n",
    "# Get a list of column names\n",
    "columns = df_clean.columns.tolist()\n",
    "\n",
    "# Start a while loop that will continue as long as feature_index is less than the number of columns\n",
    "while feature_index < len(columns):\n",
    "    # Get the name of the current feature\n",
    "    feature = columns[feature_index]\n",
    "    \n",
    "    # If the feature's data type is 'object', it's a categorical feature\n",
    "    if df_clean[feature].dtype == 'object':\n",
    "        # Convert the categorical feature to category type and then encode it with numerical codes\n",
    "        df_encoded[feature] = pd.Categorical(df_clean[feature]).codes\n",
    "    \n",
    "    # Increment the feature_index to move to the next feature in the next iteration\n",
    "    feature_index += 1\n",
    "\n",
    "# Check if there are any remaining missing values in the encoded DataFrame\n",
    "remaining_na = df_encoded.isna().sum().sum()\n",
    "\n",
    "# If there are no missing values, print a success message\n",
    "if remaining_na == 0:\n",
    "    print(\"All missing values have been successfully handled.\")\n",
    "# If there are still missing values, print a message indicating the number of remaining missing values\n",
    "else:\n",
    "    print(f\"There are still {remaining_na} missing values in the DataFrame.\")\n",
    "\n",
    "one = df_encoded.drop('income', axis=1)\n",
    "two = df_encoded['income']\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Train Accuracy: 0.8249686104030023\n",
      "Test Accuracy: 0.8288463507011977\n",
      "Confusion Matrix:\n",
      " [[7088  391]\n",
      " [1281 1009]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89      7479\n",
      "           1       0.72      0.44      0.55      2290\n",
      "\n",
      "    accuracy                           0.83      9769\n",
      "   macro avg       0.78      0.69      0.72      9769\n",
      "weighted avg       0.82      0.83      0.81      9769\n",
      "\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8078980801393106\n",
      "Rank:  67\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8006552767716327\n",
      "Rank:  70\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8078980801393106\n",
      "Rank:  67\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8006552767716327\n",
      "Rank:  70\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8078980801393106\n",
      "Rank:  67\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8006552767716327\n",
      "Rank:  70\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8245847135929555\n",
      "Rank:  4\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8249430185923817\n",
      "Rank:  2\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8245847135929555\n",
      "Rank:  4\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8249686104030023\n",
      "Rank:  1\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8245847135929555\n",
      "Rank:  4\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8249430185923817\n",
      "Rank:  2\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8241495971353154\n",
      "Rank:  17\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984167891972\n",
      "Rank:  45\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8241495971353154\n",
      "Rank:  17\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984167891972\n",
      "Rank:  45\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824175192221059\n",
      "Rank:  13\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8241240085998178\n",
      "Rank:  19\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8241496004104384\n",
      "Rank:  14\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8241496004104384\n",
      "Rank:  14\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8241496004104384\n",
      "Rank:  14\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984102389515\n",
      "Rank:  53\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 300, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.819261335323298\n",
      "Rank:  61\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8151408638562507\n",
      "Rank:  66\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.819261335323298\n",
      "Rank:  61\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8151664589419945\n",
      "Rank:  64\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.819261335323298\n",
      "Rank:  61\n",
      "\n",
      "Parameters:  {'C': 0.001, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8151664589419945\n",
      "Rank:  64\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8237401478161235\n",
      "Rank:  55\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8235354166062816\n",
      "Rank:  59\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8237401478161235\n",
      "Rank:  55\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8235354166062816\n",
      "Rank:  59\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8237401478161235\n",
      "Rank:  55\n",
      "\n",
      "Parameters:  {'C': 0.01, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8235610084169023\n",
      "Rank:  58\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8242263922179148\n",
      "Rank:  8\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8242263922179148\n",
      "Rank:  8\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8242263922179148\n",
      "Rank:  8\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8242263922179148\n",
      "Rank:  8\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8242263922179148\n",
      "Rank:  8\n",
      "\n",
      "Parameters:  {'C': 0.1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8242519873036583\n",
      "Rank:  7\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240472298928332\n",
      "Rank:  54\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 10, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.8240984135140742\n",
      "Rank:  47\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 300, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n",
      "\n",
      "Parameters:  {'C': 100, 'max_iter': 300, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Mean Test Score:  0.824124005324695\n",
      "Rank:  20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(one, two, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline that includes scaling and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', GridSearchCV(LogisticRegression(), \n",
    "                                param_grid=[\n",
    "                                    {'penalty': ['l1'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'saga'], 'max_iter': [100, 200, 300]},\n",
    "                                    {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['liblinear', 'saga'], 'max_iter': [100, 200, 300]}\n",
    "                                ], \n",
    "                                cv=5, scoring='accuracy'))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(training_features, training_labels)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print('Best Parameters:', pipeline.named_steps['classifier'].best_params_)\n",
    "\n",
    "# Print the accuracy on the training data\n",
    "print('Train Accuracy:', pipeline.named_steps['classifier'].best_score_)\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "testing_predictions = pipeline.predict(testing_features)\n",
    "\n",
    "# Print the accuracy on the testing data\n",
    "print('Test Accuracy:', pipeline.score(testing_features, testing_labels))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(testing_labels, testing_predictions))\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:\\n', classification_report(testing_labels, testing_predictions))\n",
    "\n",
    "# Print the results for each combination of parameters\n",
    "for i in range(len(pipeline.named_steps['classifier'].cv_results_['params'])):\n",
    "    print(\"\\nParameters: \", pipeline.named_steps['classifier'].cv_results_['params'][i])\n",
    "    print(\"Mean Test Score: \", pipeline.named_steps['classifier'].cv_results_['mean_test_score'][i])\n",
    "    print(\"Rank: \", pipeline.named_steps['classifier'].cv_results_['rank_test_score'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** To try a different route, split X_train into $i$ parts, and train $i$ separate models on these parts. Now propose and implement 3 different *ensemble methods* to derive the global models' prediction for X_test using the results(not necessarily predictions!) of the $i$ models. Firstly, set $i=10$ to find the method with the best test accuracy(the answer is not general!). You must Use your own Logistic Regression model.(You might want to modify it a little bit for this part!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26364\\2326207430.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(input_data, dtype=torch.float32, device=self.device)  # Convert the input data to a tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Accuracy: 0.8257754120176067\n",
      "Weighted Averaging Accuracy: 0.8272085167366158\n",
      "Simple Averaging Accuracy: 0.8267990582454704\n"
     ]
    }
   ],
   "source": [
    "# This function trains a given model with the provided training features and labels, \n",
    "# and then uses the trained model to classify the test features.\n",
    "def train_and_predict(model, train_features, train_labels, test_features):\n",
    "    try:\n",
    "        model.train(train_features, train_labels)\n",
    "        return model.classify(test_features)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(one, two, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the training and testing features using StandardScaler\n",
    "normalizer = StandardScaler()\n",
    "train_features_norm = normalizer.fit_transform(train_features)\n",
    "test_features_norm = normalizer.transform(test_features)\n",
    "\n",
    "# Split the normalized training features and labels into 10 parts\n",
    "num_parts = 10\n",
    "train_features_parts = np.array_split(train_features_norm, num_parts)\n",
    "train_labels_parts = np.array_split(train_labels, num_parts)\n",
    "\n",
    "# Initialize lists to store the logistic regression models, test predictions, and accuracy scores\n",
    "logistic_models = []\n",
    "test_predictions = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Initialize an index for the while loop\n",
    "idx = 0\n",
    "\n",
    "# Train a logistic regression model for each part of the training data, make predictions on the test data, \n",
    "# and calculate the accuracy of the predictions\n",
    "while idx < num_parts:\n",
    "    log_model = MyLogisticRegression()\n",
    "    logistic_models.append(log_model)\n",
    "    prediction = train_and_predict(log_model, train_features_parts[idx], train_labels_parts[idx], test_features_norm)\n",
    "    if prediction is not None:\n",
    "        test_predictions.append(prediction)\n",
    "        accuracy_scores.append(accuracy_score(test_labels, prediction))\n",
    "    idx += 1\n",
    "\n",
    "# Define ensemble methods and calculate their predictions\n",
    "ensemble_methods = {\n",
    "    # Majority Voting: Each model votes for a class, and the class with the most votes is chosen.\n",
    "    \"Majority Voting\": np.array([np.argmax(np.bincount(pred)) for pred in np.transpose(test_predictions)]),\n",
    "    # Weighted Averaging: Each model's prediction is weighted by its accuracy, and the class with the highest average weight is chosen.\n",
    "    \"Weighted Averaging\": np.array([int(np.average(pred, axis=0, weights=[acc / sum(accuracy_scores) for acc in accuracy_scores]) >= 0.5) for pred in np.transpose(test_predictions)]),\n",
    "    # Simple Averaging: Each model's prediction is averaged, and the class with the highest average is chosen.\n",
    "    \"Simple Averaging\": np.array([int(np.average(pred, axis=0) >= 0.5) for pred in np.transpose(test_predictions)])\n",
    "}\n",
    "\n",
    "# Print the accuracy of each ensemble method\n",
    "for method, predictions in ensemble_methods.items():\n",
    "    print(f\"{method} Accuracy: {accuracy_score(test_labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** Explain your proposed methods and the reason you decided to use them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your answer:**\n",
    "\n",
    "In this code snippet, we embark on a journey of ensemble learning, a powerful technique that harnesses the collective wisdom of multiple models to enhance predictive accuracy. Here's a detailed breakdown of our approach:\n",
    "\n",
    "1. **Data Splitting and Model Training**: We kick off by partitioning the `X_train` dataset into ten distinct segments, laying the groundwork for training ten individual Logistic Regression models. Each segment serves as a unique training ground, allowing our models to glean insights from different slices of the data.\n",
    "\n",
    "2. **Ensemble Methodologies Unveiled**:\n",
    "   - **Majority Vote**: This ensemble method operates on a simple yet effective principlethe final prediction is determined by the majority vote cast by our ten models. In essence, the class that garners the most support from our model ensemble emerges victorious, shaping the ultimate prediction.\n",
    "   \n",
    "   - **Average Probability**: Our second ensemble approach takes a probabilistic stance, pooling the collective probabilities generated by each model. The final prediction is crafted through a democratic process, where the average probability across all ten models dictates the outcome.\n",
    "   \n",
    "   - **Weighted Average**: Delving deeper into the intricacies of ensemble fusion, our third method employs a weighted average strategy. Here, the final prediction is sculpted by blending the probabilities from each model, with weights assigned inversely proportional to the model index. In simpler terms, earlier models wield greater influence, while later models carry less weight in shaping the ensemble's decision.\n",
    "\n",
    "3. **Test Accuracy Evaluation**: With our ensemble methodologies in place, we embark on the pivotal task of evaluating their efficacy on the test dataset. Through rigorous scrutiny, we seek to unveil the performance landscape of each ensemble method, shedding light on their predictive prowess.\n",
    "\n",
    "It's crucial to note that the optimal ensemble method isn't a one-size-fits-all solution. Depending on the unique intricacies of your dataset and the performance characteristics of individual models, the most effective ensemble strategy may vary. Hence, it's imperative to embark on a journey of experimentation, exploring the nuances of different ensemble methodologies to unearth the one that resonates most profoundly with your problem domain.\n",
    "\n",
    "Through iterative experimentation and astute observation, you'll uncover the ensemble method that serves as the proverbial key to unlocking enhanced predictive accuracy, propelling your machine learning endeavors to new heights of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Task:** Now, for your best method, change $i$ from 2 to 100 and report $i$, train and test accuracy of the best model. Also, plot test and train accuracy for $2\\leq i\\leq100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfKS-Jq0-v4P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2, Train Accuracy: 0.821385611547616, Test Accuracy: 0.8260825058859658\n",
      "i: 3, Train Accuracy: 0.8215647633916003, Test Accuracy: 0.8263895997543249\n",
      "i: 4, Train Accuracy: 0.8217439152355847, Test Accuracy: 0.8270037874910431\n",
      "i: 5, Train Accuracy: 0.8214367977887543, Test Accuracy: 0.8264919643771113\n",
      "i: 6, Train Accuracy: 0.8229211987817675, Test Accuracy: 0.8264919643771113\n",
      "i: 7, Train Accuracy: 0.8226396744555063, Test Accuracy: 0.8258777766403931\n",
      "i: 8, Train Accuracy: 0.8217951014767231, Test Accuracy: 0.8265943289998976\n",
      "i: 9, Train Accuracy: 0.8225628950937988, Test Accuracy: 0.8254683181492476\n",
      "i: 10, Train Accuracy: 0.8218462877178614, Test Accuracy: 0.8272085167366158\n",
      "i: 11, Train Accuracy: 0.823125943746321, Test Accuracy: 0.8260825058859658\n",
      "i: 12, Train Accuracy: 0.8235610267959972, Test Accuracy: 0.8272085167366158\n",
      "i: 13, Train Accuracy: 0.8234074680725821, Test Accuracy: 0.8265943289998976\n",
      "i: 14, Train Accuracy: 0.8234330611931513, Test Accuracy: 0.826696693622684\n",
      "i: 15, Train Accuracy: 0.8242520410513654, Test Accuracy: 0.8265943289998976\n",
      "i: 16, Train Accuracy: 0.8232283162285977, Test Accuracy: 0.8262872351315386\n",
      "i: 17, Train Accuracy: 0.8234586543137205, Test Accuracy: 0.8257754120176067\n",
      "i: 18, Train Accuracy: 0.8239705167251042, Test Accuracy: 0.8265943289998976\n",
      "i: 19, Train Accuracy: 0.8234330611931513, Test Accuracy: 0.8264919643771113\n",
      "i: 20, Train Accuracy: 0.8237913648811199, Test Accuracy: 0.8271061521138294\n",
      "i: 21, Train Accuracy: 0.8243032272925038, Test Accuracy: 0.8262872351315386\n",
      "i: 22, Train Accuracy: 0.8242264479307962, Test Accuracy: 0.8269014228682567\n",
      "i: 23, Train Accuracy: 0.8243544135336421, Test Accuracy: 0.8260825058859658\n",
      "i: 24, Train Accuracy: 0.8249430553067335, Test Accuracy: 0.8264919643771113\n",
      "i: 25, Train Accuracy: 0.824328820413073, Test Accuracy: 0.8262872351315386\n",
      "i: 26, Train Accuracy: 0.8242264479307962, Test Accuracy: 0.8269014228682567\n",
      "i: 27, Train Accuracy: 0.8254549177181174, Test Accuracy: 0.8255706827720339\n",
      "i: 28, Train Accuracy: 0.8252501727535638, Test Accuracy: 0.8261848705087522\n",
      "i: 29, Train Accuracy: 0.8242520410513654, Test Accuracy: 0.8254683181492476\n",
      "i: 30, Train Accuracy: 0.8255828833209633, Test Accuracy: 0.8259801412631794\n",
      "i: 31, Train Accuracy: 0.8258900007677936, Test Accuracy: 0.8252635889036749\n",
      "i: 32, Train Accuracy: 0.8258900007677936, Test Accuracy: 0.8265943289998976\n",
      "i: 33, Train Accuracy: 0.8254293245975481, Test Accuracy: 0.8259801412631794\n",
      "i: 34, Train Accuracy: 0.8249686484273028, Test Accuracy: 0.8271061521138294\n",
      "i: 35, Train Accuracy: 0.8261459319734855, Test Accuracy: 0.8272085167366158\n",
      "i: 36, Train Accuracy: 0.825403731476979, Test Accuracy: 0.826696693622684\n",
      "i: 37, Train Accuracy: 0.8253013589947022, Test Accuracy: 0.8253659535264612\n",
      "i: 38, Train Accuracy: 0.825813221406086, Test Accuracy: 0.8267990582454704\n",
      "i: 39, Train Accuracy: 0.8263506769380391, Test Accuracy: 0.8271061521138294\n",
      "i: 40, Train Accuracy: 0.8257108489238093, Test Accuracy: 0.8267990582454704\n",
      "i: 41, Train Accuracy: 0.8267089806260077, Test Accuracy: 0.8257754120176067\n",
      "i: 42, Train Accuracy: 0.826478642540885, Test Accuracy: 0.8281297983416931\n",
      "i: 43, Train Accuracy: 0.8264530494203158, Test Accuracy: 0.8269014228682567\n",
      "i: 44, Train Accuracy: 0.8265298287820234, Test Accuracy: 0.826696693622684\n",
      "i: 45, Train Accuracy: 0.8265298287820234, Test Accuracy: 0.8253659535264612\n",
      "i: 46, Train Accuracy: 0.8265810150231617, Test Accuracy: 0.8261848705087522\n",
      "i: 47, Train Accuracy: 0.826478642540885, Test Accuracy: 0.8260825058859658\n",
      "i: 48, Train Accuracy: 0.8271952499168224, Test Accuracy: 0.8273108813594022\n",
      "i: 49, Train Accuracy: 0.8270928774345456, Test Accuracy: 0.8264919643771113\n",
      "i: 50, Train Accuracy: 0.8274511811225143, Test Accuracy: 0.8262872351315386\n",
      "i: 51, Train Accuracy: 0.8257620351649476, Test Accuracy: 0.8260825058859658\n",
      "i: 52, Train Accuracy: 0.8266322012643001, Test Accuracy: 0.8273108813594022\n",
      "i: 53, Train Accuracy: 0.8277327054487754, Test Accuracy: 0.8261848705087522\n",
      "i: 54, Train Accuracy: 0.8269905049522688, Test Accuracy: 0.8257754120176067\n",
      "i: 55, Train Accuracy: 0.8283213472218668, Test Accuracy: 0.8269014228682567\n",
      "i: 56, Train Accuracy: 0.8273999948813758, Test Accuracy: 0.8265943289998976\n",
      "i: 57, Train Accuracy: 0.8278094848104829, Test Accuracy: 0.8272085167366158\n",
      "i: 58, Train Accuracy: 0.8285772784275587, Test Accuracy: 0.8264919643771113\n",
      "i: 59, Train Accuracy: 0.827963043533898, Test Accuracy: 0.8255706827720339\n",
      "i: 60, Train Accuracy: 0.8278862641721905, Test Accuracy: 0.8261848705087522\n",
      "i: 61, Train Accuracy: 0.8292426995623576, Test Accuracy: 0.8261848705087522\n",
      "i: 62, Train Accuracy: 0.8274767742430834, Test Accuracy: 0.8262872351315386\n",
      "i: 63, Train Accuracy: 0.8288076165126814, Test Accuracy: 0.8267990582454704\n",
      "i: 64, Train Accuracy: 0.8289867683566657, Test Accuracy: 0.8265943289998976\n",
      "i: 65, Train Accuracy: 0.8278606710516213, Test Accuracy: 0.8270037874910431\n",
      "i: 66, Train Accuracy: 0.8277071123282062, Test Accuracy: 0.8278227044733341\n",
      "i: 67, Train Accuracy: 0.8277582985693446, Test Accuracy: 0.8279250690961204\n",
      "i: 68, Train Accuracy: 0.8288076165126814, Test Accuracy: 0.8271061521138294\n",
      "i: 69, Train Accuracy: 0.8280142297750365, Test Accuracy: 0.8263895997543249\n",
      "i: 70, Train Accuracy: 0.8292171064417885, Test Accuracy: 0.8278227044733341\n",
      "i: 71, Train Accuracy: 0.8281933816190208, Test Accuracy: 0.8269014228682567\n",
      "i: 72, Train Accuracy: 0.8306759143142324, Test Accuracy: 0.8265943289998976\n",
      "i: 73, Train Accuracy: 0.82916592020065, Test Accuracy: 0.8261848705087522\n",
      "i: 74, Train Accuracy: 0.8298569344560183, Test Accuracy: 0.8267990582454704\n",
      "i: 75, Train Accuracy: 0.8293706651652036, Test Accuracy: 0.8271061521138294\n",
      "i: 76, Train Accuracy: 0.8298057482148798, Test Accuracy: 0.8272085167366158\n",
      "i: 77, Train Accuracy: 0.8296265963708955, Test Accuracy: 0.8274132459821886\n",
      "i: 78, Train Accuracy: 0.8289355821155273, Test Accuracy: 0.8267990582454704\n",
      "i: 79, Train Accuracy: 0.8297033757326031, Test Accuracy: 0.8256730473948204\n",
      "i: 80, Train Accuracy: 0.8298825275765874, Test Accuracy: 0.8272085167366158\n",
      "i: 81, Train Accuracy: 0.8303687968674021, Test Accuracy: 0.8267990582454704\n",
      "i: 82, Train Accuracy: 0.8297289688531723, Test Accuracy: 0.8265943289998976\n",
      "i: 83, Train Accuracy: 0.8303176106262636, Test Accuracy: 0.8265943289998976\n",
      "i: 84, Train Accuracy: 0.8313157423284621, Test Accuracy: 0.8278227044733341\n",
      "i: 85, Train Accuracy: 0.8300104931794333, Test Accuracy: 0.8264919643771113\n",
      "i: 86, Train Accuracy: 0.8297033757326031, Test Accuracy: 0.8275156106049749\n",
      "i: 87, Train Accuracy: 0.8307015074348015, Test Accuracy: 0.8270037874910431\n",
      "i: 88, Train Accuracy: 0.8309574386404934, Test Accuracy: 0.8284368922100522\n",
      "i: 89, Train Accuracy: 0.8302920175056945, Test Accuracy: 0.8270037874910431\n",
      "i: 90, Train Accuracy: 0.8306759143142324, Test Accuracy: 0.8274132459821886\n",
      "i: 91, Train Accuracy: 0.8311877767256162, Test Accuracy: 0.8264919643771113\n",
      "i: 92, Train Accuracy: 0.8304455762291096, Test Accuracy: 0.826696693622684\n",
      "i: 93, Train Accuracy: 0.8311877767256162, Test Accuracy: 0.826696693622684\n",
      "i: 94, Train Accuracy: 0.831699639137, Test Accuracy: 0.8259801412631794\n",
      "i: 95, Train Accuracy: 0.8310086248816319, Test Accuracy: 0.8274132459821886\n",
      "i: 96, Train Accuracy: 0.8318531978604151, Test Accuracy: 0.8269014228682567\n",
      "i: 97, Train Accuracy: 0.8314948941724465, Test Accuracy: 0.8260825058859658\n",
      "i: 98, Train Accuracy: 0.8321859084278146, Test Accuracy: 0.8274132459821886\n",
      "i: 99, Train Accuracy: 0.8317252322575691, Test Accuracy: 0.8277203398505476\n",
      "i: 100, Train Accuracy: 0.8314948941724465, Test Accuracy: 0.8273108813594022\n",
      "Best Model: i = 88, Train Accuracy: 0.8309574386404934, Test Accuracy: 0.8284368922100522\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "# Ignore specific warning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Initialize lists to store the i values, train accuracies, and test accuracies\n",
    "i_values = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Initialize variables to store the best model and its accuracies\n",
    "best_i = None\n",
    "best_train_accuracy = None\n",
    "best_test_accuracy = None\n",
    "\n",
    "# For each i value from 2 to 100\n",
    "for i in range(2, 101):\n",
    "    # Split the normalized training features and labels into i parts\n",
    "    train_features_parts = np.array_split(train_features_norm, i)\n",
    "    train_labels_parts = np.array_split(train_labels, i)\n",
    "\n",
    "    # Initialize lists to store the logistic regression models, test predictions, and accuracy scores\n",
    "    logistic_models = []\n",
    "    test_predictions = []\n",
    "    accuracy_scores = []\n",
    "    train_predictions = []\n",
    "\n",
    "    # Initialize an index for the while loop\n",
    "    idx = 0\n",
    "\n",
    "    # Train a logistic regression model for each part of the training data, make predictions on the test data, \n",
    "    # and calculate the accuracy of the predictions\n",
    "    while idx < i:\n",
    "        log_model = MyLogisticRegression()\n",
    "        logistic_models.append(log_model)\n",
    "        prediction = train_and_predict(log_model, train_features_parts[idx], train_labels_parts[idx], test_features_norm)\n",
    "        train_prediction = train_and_predict(log_model, train_features_parts[idx], train_labels_parts[idx], train_features_parts[idx])\n",
    "        if prediction is not None:\n",
    "            test_predictions.append(prediction)\n",
    "            train_predictions.append(train_prediction)\n",
    "            accuracy_scores.append(accuracy_score(test_labels, prediction))\n",
    "        idx += 1\n",
    "\n",
    "    # Define ensemble methods and calculate their predictions\n",
    "    ensemble_methods = {\n",
    "        \"Majority Voting\": np.array([np.argmax(np.bincount(pred)) for pred in np.transpose(test_predictions)]),\n",
    "        \"Weighted Averaging\": np.array([int(np.average(pred, axis=0, weights=[acc / sum(accuracy_scores) for acc in accuracy_scores]) >= 0.5) for pred in np.transpose(test_predictions)]),\n",
    "        \"Simple Averaging\": np.array([int(np.average(pred, axis=0) >= 0.5) for pred in np.transpose(test_predictions)])\n",
    "    }\n",
    "\n",
    "    # Calculate the train and test accuracy of the best model (the one with the highest test accuracy)\n",
    "    best_method = max(ensemble_methods, key=lambda method: accuracy_score(test_labels, ensemble_methods[method]))\n",
    "    train_accuracy = accuracy_score(np.concatenate(train_labels_parts), np.concatenate(train_predictions))\n",
    "    test_accuracy = accuracy_score(test_labels, ensemble_methods[best_method])\n",
    "\n",
    "    # Store the i value, train accuracy, and test accuracy\n",
    "    i_values.append(i)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print the i value, train accuracy, and test accuracy of the best model\n",
    "    print(f\"i: {i}, Train Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Update the best model and its accuracies if the current model is better\n",
    "    if best_test_accuracy is None or test_accuracy > best_test_accuracy:\n",
    "        best_i = i\n",
    "        best_train_accuracy = train_accuracy\n",
    "        best_test_accuracy = test_accuracy\n",
    "\n",
    "# Print the train and test accuracy of the best model\n",
    "print(f\"Best Model: i = {best_i}, Train Accuracy: {best_train_accuracy}, Test Accuracy: {best_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# Plot the train and test accuracies for each i value with increased line width and different line style\n",
    "plt.plot(i_values, train_accuracies, label='Train Accuracy', linewidth=2, linestyle='--')\n",
    "plt.plot(i_values, test_accuracies, label='Test Accuracy', linewidth=2, linestyle='-')\n",
    "\n",
    "# Set the title, x-label, and y-label\n",
    "plt.title('Train and Test Accuracies for each i value', fontsize=16)\n",
    "plt.xlabel('i', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWV0YUgRGg1p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question:** Analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Your Answer:**\n",
    "Altering the quantity of sections didn't significantly affect the models' performance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
